#!/usr/bin/env node

var csv = require('csv');
var events = require('events');
var winston = require('winston');
var path = require('path');
var argv = require('optimist')
    .usage("Usage: $0 -u [username] -p [password] > out.csv")
    .demand(['u', 'p'])
    .default('archivedir', path.join(process.cwd(), 'scraped_data')
)
    .default('inputdir', path.join(process.cwd(), 'input_data')
    .default('fromfiles', false)
    .default('logfile', path.join(process.cwd(), 'scrape_ec_data.log'))
    .argv;
var _ = require('underscore'); 
var async = require('async');
var dataset = require('../lib/dataset');
var DataMerger = require('../lib/merger').DataMerger;

var globalOpts = {
  // Filename of file that contains only early childhood programs within 
  // ESD's geographic zone of interest for site visits.
  inZoneFilename: 'All_inzone.csv'
};
var output = csv().to.stream(process.stdout);
var numZips = 0;
var zipSeen = {};
var zipsFetched = 0;
var recordsFetched = 0;
var numProfiles = 0;
var profilesFetched = 0;
var fetchedStateData = false;
var delay = 1000;
var start;
var scheduler = (function () {
  var requestQueue = async.queue(function(task, callback) {
    task();
    setTimeout(callback, delay);
  }, 1);

  return { 
    schedule: function(fn) {
      // If we're loading data from files, no need to delay
      if (globalOpts.fromFiles) {
        fn();
        return;
      }

      requestQueue.push(fn);
    }
  };
}());
var hasErrs = false;

// Set up logging
winston.add(winston.transports.File, { filename: argv.logfile });
winston.remove(winston.transports.Console);

function writeRow(data) {
  if(_.isUndefined(writeRow.headerWritten)) {
    output.write(dataset.FIELDS);
    writeRow.headerWritten = true;
  }

  output.write(data);
}

var merger = new DataMerger(['cdc', 'quicksearch', 'profile']);
merger.on('update', function(slug, key, data, count) {
  var qsData;
  if (count == 2) {
    // We have both a LicenseNumber and an ProviderID for this record. now
    // we can get the profile 
    numProfiles++;
    qsData = merger.get('quicksearch', key); 
    scheduler.schedule(function() {
      getGSCProfile(key, qsData.GSCProviderID);
    });
  }
})
.on('merged', function(licenseNum, data) {
  // We've gotten a record from all datasets. We can write the row.
  writeRow(data);
});

function checkDone() {
  if (fetchedStateData && merger.merged >= numProfiles) {
    done();
  }
  winston.log('info', "%d/%d zips, %d/%d profiles fetched", zipsFetched, numZips, profilesFetched, numProfiles);
}

function done() {
  var now;
  var elapsed;
  
  // There are likely some records in the state dataset that don't have
  // corresponding GSC records.  Include them anyway.
  merger.ids('cdc').forEach(function(key) {
    if (!merger.has('quicksearch', key)) {
      writeRow(merger.get('cdc', key));
    }
  });

  now = new Date();
  elapsed = now - start;
  winston.log("info", "Scraping run finished in " + elapsed + " milliseconds"); 

  if (hasErrs) {
    process.exit(1);
  }
}

function getGSCProfile(licenseNum, providerId) {
  var filename;
  var gscData = new dataset.GSCProfileDataset()
    .on('data', function(data) {
      winston.log("info", "Got GSC profile data for %s (%s)", licenseNum, providerId);
      merger.update('profile', data.LicenseNumber, data);
      profilesFetched++;
    })
    .on('end', function() {
      checkDone();
    })
    .on('error', function(err) {
      winston.error(err);
      hasErrs = true;
    });

  if (globalOpts.fromFiles) {
    filename = path.join(globalOpts.archiveDir, providerId + '.html');
    winston.log('info', "Fetching GSC profile data for %s from file %s", licenseNum, filename);
    gscData.fromFile(filename);
  }
  else {
    gscData.fromURL(null, {
      username: globalOpts.username, 
      password: globalOpts.password, 
      archiveDir: globalOpts.archiveDir,
      providerId: providerId
    });
  }

  return gscData;
}

function getGSCDataForZip(zip) {
  var filename;
  var criteria = _.clone(dataset.BASE_CRITERIA);

  criteria.SEARCHTYPE = 'Zip';
  criteria.ZIP = zip;

  var gscData = new dataset.GSCQuicksearchDataset()
    .on('data', function(data) {
      merger.update('quicksearch', data.LicenseNumber, data);
    })
    .on('end', function() {
      winston.log("info", "Got GSC data for %s", zip);
      zipsFetched++;
      checkDone();
    })
    .on('error', function(err) {
      winston.error(err);
      hasErrs = true;
    });

  if (globalOpts.fromFiles) {
    filename = path.join(globalOpts.archiveDir, zip + '.json');
    winston.log("info", "Fetching GSC data for %s from file %s", zip, filename);
    gscData.fromFile(filename);
  }
  else {
    winston.log("info", "Fetching GSC data for %s", zip);
    gscData.fromURL(null, {
      username: globalOpts.username, 
      password: globalOpts.password, 
      archiveDir: globalOpts.archiveDir,
      criteria: criteria
    });
  }

  return gscData;
}

_.extend(globalOpts, {
  username: argv.u,
  password: argv.p,
  archiveDir: argv.archivedir,
  inputDir: argv.inputdir,
  fromFiles: argv.fromfiles
});

winston.info("Starting scraping run");
start = new Date();
var inZoneData = new dataset.InZoneDataset()
  .on('data', function(data) {
    merger.update('inzone', data.LicenseNumber, data);
  });
var stateData = new dataset.CDCDataset()
  .on('data', function(data) {
    recordsFetched++;
    merger.update('cdc', data.LicenseNumber, data);
    var zip = data.ZipCode.toString();
    if (_.isUndefined(zipSeen[zip])) {
      zipSeen[zip] = true;
      numZips++;
      scheduler.schedule(function() {
        getGSCDataForZip(zip);
      });
    }
  })
  .on('end', function() {
    var inZonePath = path.join(globalOpts.inputDir, 
                               globalOpts.inZoneFilename);
    fetchedStateData = true;
  })
  .on('error', function(err) {
    winston.error(err);
    hasErrs = true;
  });

if (globalOpts.fromFiles) {
  stateData.fromFile(path.join(globalOpts.archiveDir, 'cdc.txt'));
}
else {
  stateData.fromURL(null, {
    archiveDir: globalOpts.archiveDir
  });
}
